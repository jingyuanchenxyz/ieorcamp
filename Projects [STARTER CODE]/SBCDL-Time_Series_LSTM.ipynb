{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3077b84-9815-4835-aa91-4c80b17d36aa",
   "metadata": {},
   "source": [
    "# This project is about predicting the temperature 12 hours from now given a set of past features. The data is from Germany for about 7 years at the hourly granularity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4089d35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import imdb\n",
    "from keras.utils import timeseries_dataset_from_array\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e9b0d1-45ff-45df-97bf-dd89bb056eea",
   "metadata": {},
   "source": [
    "# Read the data from the csv file (do not worry); the header gives you the meaning of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8e70fa-99f8-4728-87dc-da547bd1eb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "fname = list(uploaded.keys())[0]  # Get the uploaded filename\n",
    "with open(fname) as f:\n",
    "    data = f.read()\n",
    "lines = data.split(\"\\n\")\n",
    "header = lines[0].split(\",\")\n",
    "lines = lines[1:]\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f934cc8d-3a67-4a9d-b944-f4a8c621edd0",
   "metadata": {},
   "source": [
    "# These lines compute the temperature (the target) and the raw_data (the features). The raw_data also contains the temperature since past temperature will be used to predict the next temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58a4dab-21d0-4465-87e5-acdb03ae27cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = np.zeros((len(lines),))\n",
    "raw_data = np.zeros((len(lines), len(header) - 1))\n",
    "for i, line in enumerate(lines):\n",
    "    values = [float(x) for x in line.split(\",\")[1:]]\n",
    "    temperature[i] = values[1]\n",
    "    raw_data[i, :] = values[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2876719e-570c-46ce-9446-5c4d20023b02",
   "metadata": {},
   "source": [
    "# Normalize the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cbbbda-7a49-4725-9a74-978b6f621d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = raw_data[:num_train_samples].mean(axis=0)\n",
    "raw_data -= mean\n",
    "std = raw_data[:num_train_samples].std(axis=0)\n",
    "raw_data /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fc05f6-ae30-4d49-9a24-36fb76c178b0",
   "metadata": {},
   "source": [
    "# Define the proper number of samples for the training, testing, and validation sets; do not create new sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ee745e-438c-4efc-ac64-61445cdded38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the list 'lines' to build your 3 datasets. 70% of the length of lines should be the training dataset, 20% validation dataset, and the remaining 10% testing dataset\n",
    "num_train_samples = \n",
    "num_val_samples = \n",
    "num_test_samples = \n",
    "print(\"num_train_samples:\", num_train_samples)\n",
    "print(\"num_val_samples:\", num_val_samples)\n",
    "print(\"num_test_samples:\", num_test_samples)\n",
    "print(\"total:\",num_train_samples + num_val_samples + num_test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e936a41-4520-46bb-9c1c-48a9fdbb517b",
   "metadata": {},
   "source": [
    "# This is the utility code to generate the data as discussed in the videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3978addb-31db-4211-b304-a1f7b1d8113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 120\n",
    "lookahead = 12 # predict 12 hours in the future\n",
    "delay = (sequence_length + lookahead - 1)\n",
    "batch_size = 256\n",
    "\n",
    "train_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "    raw_data[:-delay],\n",
    "    targets=temperature[delay:],\n",
    "    sequence_length=sequence_length,\n",
    "    batch_size=batch_size,\n",
    "    start_index=0,\n",
    "    end_index=num_train_samples-1)\n",
    "\n",
    "val_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "    raw_data[:-delay],\n",
    "    targets=temperature[delay:],\n",
    "    sequence_length=sequence_length,\n",
    "    batch_size=batch_size,\n",
    "    start_index=num_train_samples,\n",
    "    end_index=num_train_samples + num_val_samples-1)\n",
    "\n",
    "test_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "    raw_data[:-delay],\n",
    "    targets=temperature[delay:],\n",
    "    sequence_length=sequence_length,\n",
    "    batch_size=batch_size,\n",
    "    start_index=num_train_samples + num_val_samples,\n",
    "    end_index=num_train_samples + num_val_samples + num_test_samples-delay-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4a0dc2-730c-4ce4-b135-754e6539f5c0",
   "metadata": {},
   "source": [
    "# Now define the LSTM model, plot the results;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74005da7-e896-4c42-bcc3-bd7a1f2e7198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_mae = ...\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test MAE: {test_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a05e48-3672-49c3-bd38-e085027e617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for the test dataset\n",
    "predictions = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf0ef36-933d-4547-997f-2ad3f9a3cd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs. predicted temperature values\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a140b5db-adf6-41a1-950f-538349230d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_temperatures = temperature[num_train_samples + num_val_samples + delay : num_train_samples + num_val_samples + num_test_samples]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(actual_temperatures, label=\"Actual Temperature\", alpha=0.7)\n",
    "plt.plot(predictions, label=\"Predicted Temperature\", alpha=0.7)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Temperature (Â°C)\")\n",
    "plt.legend()\n",
    "plt.title(\"Test Dataset: Actual vs. Predicted Temperature\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
